{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import pickle \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJ_PATH = '/proj/rcs-hdd/kpei/symmetry_source_dataset/training_result/adj_matrices'\n",
    "TEXT_FILE = '/proj/rcs-hdd/kpei/symmetry_source_dataset/training_result/train.code'\n",
    "LABELS_FILE = '/proj/rcs-hdd/kpei/symmetry_source_dataset/training_result/train.tgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEXT_FILE, 'r') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LABELS_FILE, 'r') as f:\n",
    "    labels = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_inds(line):\n",
    "    return [0] + [i + 1 for i, token in enumerate(line[:-1]) if token == '\\\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "permutations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invariant_permutations(adj, max_permutations):\n",
    "    n_lines = len(adj)\n",
    "    indegrees = [sum(col) for col in zip(*adj)]\n",
    "    curr = []\n",
    "    invariant_permutations = []\n",
    "\n",
    "    def __generate_topo_orderings():\n",
    "        if len(invariant_permutations) == max_permutations:\n",
    "            return\n",
    "        if len(curr) == n_lines:\n",
    "            invariant_permutations.append(tuple(curr[:]))\n",
    "            return\n",
    "        for node, ind in enumerate(indegrees):\n",
    "            if node in curr:\n",
    "                continue\n",
    "            if ind == 0:\n",
    "                curr.append(node)\n",
    "                for node_dest, is_edge in enumerate(adj[node]):\n",
    "                    if is_edge == 1:\n",
    "                        indegrees[node_dest] -= 1\n",
    "                __generate_topo_orderings()\n",
    "                curr.pop()\n",
    "                for node_dest, is_edge in enumerate(adj[node]):\n",
    "                    if is_edge == 1:\n",
    "                        indegrees[node_dest] += 1\n",
    "    __generate_topo_orderings()\n",
    "    return invariant_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(i, n_permutations):\n",
    "    adj_old = np.load(os.path.join(ADJ_PATH, f'{i}.npz'))['arr_0']\n",
    "    tokens = data[i].split(' ')[:-1]\n",
    "    label = labels[i][:-1]\n",
    "    tokens = ['\\n' if t == '\\\\n' else t for t in tokens]\n",
    "    line_inds = [0] + [i + 1 for i, token in enumerate(tokens[:-1]) if token == '\\n'] # beginning index of each new line\n",
    "    num_lines = len(line_inds)\n",
    "    lines = [' '.join(tokens[line_inds[i]:line_inds[i+1]]) for i in range(len(line_inds) - 1)] + [' '.join(tokens[line_inds[-1]:])]\n",
    "    adj_new = [[0]*num_lines for _ in range(num_lines)]\n",
    "    for adj_new_row in range(num_lines): # fill in each row of new adj matrix\n",
    "        adj_old_row = line_inds[adj_new_row] \n",
    "        for adj_new_dest, line_ind in enumerate(line_inds):\n",
    "            if adj_old[adj_old_row][line_ind] == 1:\n",
    "                adj_new[adj_new_row][adj_new_dest] = 1\n",
    "    permutations = get_invariant_permutations(adj_new, n_permutations)\n",
    "    return lines, permutations, label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 64\n",
    "\n",
    "code_per_thread = [[] for _ in range(N_THREADS)]\n",
    "permutations_per_thread = [[] for _ in range(N_THREADS)]\n",
    "labels_per_thread = [[] for _ in range(N_THREADS)]\n",
    "\n",
    "num_per_thread = len(data) // N_THREADS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESSES = 64\n",
    "MAX_PERMUTATIONS = 4\n",
    "\n",
    "process_args = [(i, MAX_PERMUTATIONS) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(NUM_PROCESSES) as p: \n",
    "    processed_data = p.starmap(process, process_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = [{\n",
    "    'code': line, \n",
    "    'permutations': permutations,\n",
    "    'label': label\n",
    "} for (line, permutations, label) in processed_data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE_PATH = '/proj/rcs-hdd/aj3051/symmetry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_data = pickle.dumps(processed_data)\n",
    "with open(os.path.join(STORAGE_PATH, 'data.pickle'), 'wb') as f:\n",
    "    f.write(serialized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_processed_data(processed_data):\n",
    "    filtered_data = [] \n",
    "    for (line, permutations, label) in processed_data:\n",
    "        if len(permutations) == MAX_PERMUTATIONS: \n",
    "            filtered_data.append({\n",
    "                'code': line, \n",
    "                'permutations': permutations,\n",
    "                'label': label\n",
    "            })\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filter_processed_data(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pickle.dumps(filtered_data)\n",
    "with open(os.path.join(STORAGE_PATH, 'data_four_permutations.pickle'), 'wb') as f:\n",
    "    f.write(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aj3051/anaconda3/envs/backpack/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/aj3051/anaconda3/envs/backpack/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(STORAGE_PATH, 'data_four_permutations.pickle'), 'rb')  as f:\n",
    "    filtered_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['void ( ) { \\n',\n",
       "  'Map < String , Object > vars = new Hash Map < String , Object > ( ) ; \\n',\n",
       "  'Map < String , Object > ctx = new Hash Map < String , Object > ( ) ; \\n',\n",
       "  'Map < String , Object > obj 1 = new Hash Map < String , Object > ( ) ; \\n',\n",
       "  'obj 1 . put ( \"prop1\" , \"value1\" ) ; \\n',\n",
       "  'ctx . put ( \"obj1\" , obj 1 ) ; \\n',\n",
       "  'vars . put ( \"ctx\" , ctx ) ; \\n',\n",
       "  'Executable Script executable = se . executable ( new Compiled Script ( Script Service . Script Type . INLINE , \"testJavaScriptObjectMapInter\" , \"js\" , se . compile ( \"ctx.obj2_=_{};_ctx.obj2.prop2_=_\\'value2\\';_ctx.obj1.prop1_=_\\'uvalue1\\'\" , Collections . empty Map ( ) ) ) , vars ) ; \\n',\n",
       "  'executable . run ( ) ; \\n',\n",
       "  'ctx = ( Map < String , Object > ) executable . unwrap ( vars . get ( \"ctx\" ) ) ; \\n',\n",
       "  'assert That ( ctx . contains Key ( \"obj1\" ) , equal To ( true ) ) ; \\n',\n",
       "  'assert That ( ( String ) ( ( Map < String , Object > ) ctx . get ( \"obj1\" ) ) . get ( \"prop1\" ) , equal To ( \"uvalue1\" ) ) ; \\n',\n",
       "  'assert That ( ctx . contains Key ( \"obj2\" ) , equal To ( true ) ) ; \\n',\n",
       "  'assert That ( ( String ) ( ( Map < String , Object > ) ctx . get ( \"obj2\" ) ) . get ( \"prop2\" ) , equal To ( \"value2\" ) ) ; \\n',\n",
       "  '} \\n'],\n",
       " [(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14),\n",
       "  (0, 1, 3, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14),\n",
       "  (0, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14),\n",
       "  (0, 2, 3, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)],\n",
       " 'testJavaScriptObjectMapInter')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('backpack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e552d307c8781d98a1345404e47beeec67d0c4ac0bb536f85b4d3cc6c64bd723"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
